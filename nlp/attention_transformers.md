# Books
- Natural Language Processing with Transformers, Revised Edition Chapters 1 and 3

# Papers
- [Attention Is All You Need](https://proceedings.neurips.cc/paper/2017/file/3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf)
- [Formal Algorithms for Transformers](https://arxiv.org/pdf/2207.09238.pdf)
- [Transformers: State-of-the-Art Natural Language Processing](https://aclanthology.org/2020.emnlp-demos.6.pdf)

# Web
- [Jay Alammar: illustrated-transformer](https://jalammar.github.io/illustrated-transformer/) 
- [Jay Alammar: visualizing-neural-machine-translation](https://jalammar.github.io/visualizing-neural-machine-translation-mechanics-of-seq2seq-models-with-attention/)
- [Transformers from Scratch](https://peterbloem.nl/blog/transformers) 
- [Pinecone: Transformers](https://www.pinecone.io/learn/transformers/)

# Video
- [Yannic Kilcher: Attention Is All You Need](https://www.youtube.com/watch?v=iDulhoQ2pro) 
- [Andrej Karpathy: Let's build GPT: from scratch, in code, spelled out](https://www.youtube.com/watch?v=kCc8FmEb1nY) 