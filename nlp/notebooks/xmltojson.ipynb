{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 497,
   "id": "45890d9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xmltodict\n",
    "import os\n",
    "import json\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import torch\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 498,
   "id": "f5f49811",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Enabling notebook extension jupyter-js-widgets/extension...\n",
      "      - Validating: \u001b[32mOK\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!jupyter nbextension enable --py widgetsnbextension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 499,
   "id": "82b26816",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/Users/mokarakaya/develop/dataset/sem_eval/sem_eval/Restaurants_Train_v2.xml') as file:\n",
    "     xmlfile = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 500,
   "id": "5b571ac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = json.dumps(xmltodict.parse(xmlfile))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 501,
   "id": "c10d4100",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = json.loads(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 502,
   "id": "f66c8318",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = sentences[\"sentences\"][\"sentence\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 503,
   "id": "b13f95c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = []\n",
    "feature = []\n",
    "for sent in sentences:\n",
    "#     print(sent)\n",
    "    text = sent[\"text\"]\n",
    "    if \"aspectTerms\" in sent:\n",
    "        terms = sent[\"aspectTerms\"][\"aspectTerm\"]\n",
    "        if type(terms) == dict:\n",
    "            terms = [terms[\"@term\"]]\n",
    "        elif type(terms) == list:\n",
    "            terms = [t[\"@term\"] for t in terms]\n",
    "        else: \n",
    "            raise ValueError()\n",
    "    else:\n",
    "        terms = []\n",
    "    vec = CountVectorizer(analyzer='word', ngram_range=(1, 4)).fit([text])\n",
    "    ngrams = vec.get_feature_names()\n",
    "    s.extend(ngrams)\n",
    "    feature.extend([ngram in terms for ngram in ngrams])\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 504,
   "id": "c5c9c442",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_encoder = SentenceTransformer(\"sentence-transformers/paraphrase-xlm-r-multilingual-v1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 505,
   "id": "59fba372",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_index = int(len(s) * 0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 506,
   "id": "dd9d0648",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_s = s[:train_index]\n",
    "train_f = feature[:train_index]\n",
    "test_s = s[train_index:]\n",
    "test_f = feature[train_index:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 507,
   "id": "07d11098",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_false = np.argwhere(np.array(train_f) == False)[:,0]\n",
    "t_remove = t_false[np.random.choice(len(t_false), size=90000, replace=False)]\n",
    "t_keep = np.delete(np.arange(len(train_f)), t_remove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 508,
   "id": "b53e7a7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_s_removed = np.array(train_s)[t_keep]\n",
    "train_f_removed = np.array(train_f)[t_keep]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 509,
   "id": "ef527623",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e256f7c2810466a84edd83ec19d8119",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/152 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "encoded = model_encoder.encode(train_s_removed, show_progress_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 510,
   "id": "0d5b055c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mokarakaya/opt/anaconda3/envs/develop/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "clf = LogisticRegression(random_state=0).fit(encoded, train_f_removed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 511,
   "id": "86e14ff6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b98acd5c5b584c579925c7ae07a9ffb6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([ True])"
      ]
     },
     "execution_count": 511,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict(model_encoder.encode([\"sandwich\"], show_progress_bar=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 512,
   "id": "6313f893",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4d4b5b1854c4aacb0c34e1c81c3990d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1271 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.9288367402159742"
      ]
     },
     "execution_count": 512,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_s_encoded = model_encoder.encode(test_s, show_progress_bar=True)\n",
    "clf.score(test_s_encoded, test_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 513,
   "id": "40c6bc30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[36827,  2861],\n",
       "       [   32,   933]])"
      ]
     },
     "execution_count": 513,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = clf.predict(test_s_encoded)\n",
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(test_f, p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 534,
   "id": "813c144e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e72d84d852e14439b2f9190d9c2d4d43",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[('best', False),\n",
       " ('best service', False),\n",
       " ('best service ever', False),\n",
       " ('ever', False),\n",
       " ('service', True),\n",
       " ('service ever', False)]"
      ]
     },
     "execution_count": 534,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_features(text,c):\n",
    "    vec = CountVectorizer(analyzer='word', ngram_range=(1, 4)).fit([text])\n",
    "    ngrams = vec.get_feature_names()\n",
    "    predictions = c.predict(model_encoder.encode(ngrams, show_progress_bar=True))\n",
    "    return zip(ngrams, predictions)\n",
    "list(get_features(\"Best service ever\", clf))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 518,
   "id": "974547df",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mokarakaya/opt/anaconda3/envs/develop/lib/python3.8/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04611695307647a9a97b7e0987cde2bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[('best', False),\n",
       " ('best service', False),\n",
       " ('best service ever', False),\n",
       " ('ever', False),\n",
       " ('service', True),\n",
       " ('service ever', False)]"
      ]
     },
     "execution_count": 518,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "clf_mlp = MLPClassifier(random_state=1, max_iter=300).fit(encoded, train_f_removed)\n",
    "list(get_features(\"Best service ever\", clf_mlp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 549,
   "id": "8a9a0e0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[37874  1814]\n",
      " [   48   917]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/y5/csvmgkln6cl70_qlk62pc7c80000gn/T/ipykernel_2681/2095902560.py:5: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  cm.astype(np.float).sum(axis=1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([39688.,   965.])"
      ]
     },
     "execution_count": 549,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_mlp = clf_mlp.predict(predictions)\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(test_f, p_mlp)\n",
    "print(cm)\n",
    "cm.astype(np.float).sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 520,
   "id": "2444ab65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9541977221853246"
      ]
     },
     "execution_count": 520,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_mlp.score(test_s_encoded, test_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 569,
   "id": "8e48468e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(Model, self).__init__()\n",
    "        self.layer1 = nn.Linear(input_dim, 50)\n",
    "#         self.layer2 = nn.Linear(50, 50)\n",
    "        self.layer3 = nn.Linear(50, 2)\n",
    "#         self.layer3 = nn.Linear(50, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.layer1(x))\n",
    "#         x = F.relu(self.layer2(x))\n",
    "        x = F.softmax(self.layer3(x), dim=1)\n",
    "#         x = torch.sigmoid(self.layer3(x))\n",
    "        return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 570,
   "id": "26f795ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_f_p = [[0,1] if t else [1,0] for t in train_f]\n",
    "# test_f_p = [[0,1] if t else [1,0] for t in test_f]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 571,
   "id": "3db2233f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "test_f_np = np.array(list(map(int, test_f)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 572,
   "id": "1186aa98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4857\n",
      "4857\n"
     ]
    }
   ],
   "source": [
    "print(len(encoded_removed))\n",
    "print(len(train_f_removed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 573,
   "id": "dac2b742",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train = Variable(torch.from_numpy(encoded)).float()\n",
    "X_train = Variable(torch.from_numpy(encoded_removed)).float()\n",
    "# y_train = Variable(torch.from_numpy(np.array(train_f))).long()\n",
    "# y_train = Variable(torch.from_numpy(np.array(train_f))).float()\n",
    "# y_train = Variable(torch.from_numpy(train_f_removed)).float()\n",
    "y_train = Variable(torch.from_numpy(train_f_removed)).long()\n",
    "X_test = Variable(torch.from_numpy(test_s_encoded)).float()\n",
    "y_test = Variable(torch.from_numpy(test_f_np)).long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 574,
   "id": "378e1482",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(965)"
      ]
     },
     "execution_count": 574,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 575,
   "id": "97cd1a79",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(X_train.shape[1])\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# loss_fn = nn.BCELoss()\n",
    "# loss_fn = nn.BCEWithLogitsLoss()\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "EPOCHS = 100\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fe843a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 576,
   "id": "984f6d66",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:05<00:00, 16.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.97621334 0.97586894 0.97296631 0.95503408 0.92738545 0.90000737\n",
      " 0.8726539  0.84758812 0.82121861 0.79816985 0.78311563 0.77140677\n",
      " 0.75736105 0.74481589 0.73549306 0.72678524 0.71057487 0.69925958\n",
      " 0.68976462 0.68496788 0.68226206 0.67837554 0.67205369 0.66725701\n",
      " 0.66401005 0.65596634 0.65362948 0.6516124  0.64971834 0.64347035\n",
      " 0.64177305 0.63562346 0.63353258 0.63176149 0.63082677 0.62976903\n",
      " 0.62718618 0.62536591 0.62359482 0.62192214 0.62381619 0.61867511\n",
      " 0.61761737 0.61638749 0.61385381 0.61321425 0.61365706 0.61215657\n",
      " 0.60974592 0.61055768 0.60878658 0.60952449 0.60492462 0.60637593\n",
      " 0.59995574 0.59980816 0.59983271 0.59897178 0.59870118 0.59808624\n",
      " 0.59646273 0.60010332 0.59223181 0.60305512 0.58389294 0.60669571\n",
      " 0.58408976 0.59744668 0.5958724  0.5859592  0.60089046 0.585787\n",
      " 0.59392911 0.5938307  0.58022779 0.5974713  0.57789093 0.58881265\n",
      " 0.58610678 0.57476693 0.59257621 0.57171673 0.58074433 0.57548028\n",
      " 0.57474232 0.57936686 0.57139695 0.58354855 0.5694291  0.58062136\n",
      " 0.57122475 0.57572627 0.57233167 0.57036382 0.57484072 0.56158215\n",
      " 0.58069515 0.5575726  0.58138388 0.56394362]\n",
      "[0.69142431 0.6899814  0.6886785  0.6874187  0.68619418 0.68498462\n",
      " 0.68379223 0.68262929 0.68147504 0.68034697 0.67924601 0.67815816\n",
      " 0.67708808 0.67603838 0.67499888 0.67397124 0.67295218 0.67195034\n",
      " 0.67094773 0.66994923 0.66895509 0.66796368 0.66696978 0.66596895\n",
      " 0.66496724 0.66396481 0.66295457 0.66194165 0.66092575 0.65990514\n",
      " 0.65887487 0.65784103 0.65680492 0.65575933 0.65471256 0.65366131\n",
      " 0.65260071 0.65153587 0.65046602 0.64938951 0.64830357 0.64721429\n",
      " 0.64611578 0.6450128  0.64390165 0.64278102 0.64165556 0.64051771\n",
      " 0.63937199 0.6382187  0.63705838 0.63589734 0.6347301  0.6335544\n",
      " 0.63238096 0.63120383 0.63002312 0.62883741 0.62764657 0.62645227\n",
      " 0.62525237 0.62405109 0.62284976 0.62164891 0.62046075 0.61929107\n",
      " 0.61812645 0.61693531 0.61571664 0.61453688 0.6133939  0.61224413\n",
      " 0.61106622 0.60987884 0.60871744 0.60757679 0.60642493 0.60524786\n",
      " 0.60407364 0.60291862 0.60177583 0.60063624 0.59948248 0.59831756\n",
      " 0.59716111 0.59601337 0.59487951 0.59375668 0.59263551 0.59151053\n",
      " 0.59037602 0.58923846 0.58811396 0.58700109 0.58590013 0.58480841\n",
      " 0.58374012 0.58269221 0.5816499  0.58056486]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "loss_list = np.zeros((EPOCHS,))\n",
    "accuracy_list = np.zeros((EPOCHS,))\n",
    "\n",
    "for epoch in tqdm.trange(EPOCHS):\n",
    "    y_pred = model(X_train)\n",
    "#     print(y_pred[:,0])\n",
    "#     loss = loss_fn(y_pred[:,0], y_train)\n",
    "    loss = loss_fn(y_pred, y_train)\n",
    "#     print(loss)\n",
    "    loss_list[epoch] = loss.item()\n",
    "\n",
    "    # Zero gradients\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        y_pred = model(X_test)\n",
    "        correct = (torch.argmax(y_pred, dim=1) == y_test).type(torch.FloatTensor)\n",
    "#         y_pred_bin = [True if x >= 0.5 else False for x in y_pred[:,0].tolist()]\n",
    "#         correct = (np.array(y_pred_bin) == np.array(y_test))\n",
    "        accuracy_list[epoch] = correct.mean()\n",
    "print(accuracy_list)\n",
    "print(loss_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 577,
   "id": "0a17ad0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23053"
      ]
     },
     "execution_count": 577,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([1 if x >= 0.5 else 0 for x in y_pred[:,0].tolist()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 581,
   "id": "0445aeae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[22507 17181]\n",
      " [  546   419]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/y5/csvmgkln6cl70_qlk62pc7c80000gn/T/ipykernel_2681/3691915387.py:5: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  cm /  cm.astype(np.float).sum(axis=1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[5.67098367e-01, 1.78041451e+01],\n",
       "       [1.37573070e-02, 4.34196891e-01]])"
      ]
     },
     "execution_count": 581,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model(X_test)\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(test_f_np, torch.argmax(y_pred, dim=1).tolist())\n",
    "print(cm)\n",
    "cm /  cm.astype(np.float).sum(axis=1)\n",
    "# confusion_matrix(test_f_np, [1 if x >= 0.5 else 0 for x in y_pred[:,0].tolist()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 579,
   "id": "cba53955",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 2])\n",
      "torch.Size([2])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.31326165795326233"
      ]
     },
     "execution_count": 579,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = nn.CrossEntropyLoss()\n",
    "input = torch.from_numpy(np.array([[1.0,0.0], [0.0,1.0]])).float()\n",
    "print(input.size())\n",
    "target = torch.from_numpy(np.array([0, 1])).long()\n",
    "print(target.size())\n",
    "loss(input, target).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 532,
   "id": "d61c0aac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2])\n",
      "torch.Size([2])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "50.0"
      ]
     },
     "execution_count": 532,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss =  nn.BCELoss()\n",
    "input = torch.from_numpy(np.array([0,1])).float()\n",
    "print(input.size())\n",
    "target = torch.from_numpy(np.array([1, 1])).float()\n",
    "print(target.size())\n",
    "loss(input, target).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 540,
   "id": "45d7844c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1f564c94b6c42d48fb64bea3a98ecdc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[('best', tensor([0.0022, 0.6325], grad_fn=<UnbindBackward>)),\n",
       " ('best service', tensor([0.0046, 0.2798], grad_fn=<UnbindBackward>)),\n",
       " ('best service ever', tensor([0.0264, 0.0523], grad_fn=<UnbindBackward>)),\n",
       " ('ever', tensor([0.1908, 0.0091], grad_fn=<UnbindBackward>)),\n",
       " ('service', tensor([0.0861, 0.0233], grad_fn=<UnbindBackward>)),\n",
       " ('service ever', tensor([0.6900, 0.0031], grad_fn=<UnbindBackward>))]"
      ]
     },
     "execution_count": 540,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_features_pytorch(text,c):\n",
    "    vec = CountVectorizer(analyzer='word', ngram_range=(1, 4)).fit([text])\n",
    "    ngrams = vec.get_feature_names()\n",
    "    X = Variable(torch.from_numpy(np.array([model_encoder.encode(ngrams, show_progress_bar=True)]))).float()\n",
    "    predictions = model(X)\n",
    "    return zip(ngrams, predictions[0])\n",
    "list(get_features_pytorch(\"Best service ever\", model))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18996460",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
